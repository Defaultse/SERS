{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.mixture import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn import preprocessing\n",
    "from pydub import AudioSegment\n",
    "\n",
    "wavFile=\"C:/Users/User/Desktop/diploma/voice-patrol/backend/speech-diarization/M_0073_12y5m_1.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55beb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "segLen,frameRate,numMix = 3,50,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa981eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VoiceActivityDetection(wavData, frameRate):\n",
    "    # uses the librosa library to compute short-term energy\n",
    "    ste = librosa.feature.rms(wavData,hop_length=int(16000/frameRate)).T\n",
    "    thresh = 0.1*(np.percentile(ste,97.5) + 9*np.percentile(ste,2.5))    # Trim 5% off and set threshold as 0.1x of the ste range\n",
    "    return (ste>thresh).astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e43f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavData,_ = librosa.load(wavFile,sr=16000)\n",
    "%time vad=VoiceActivityDetection(wavData,frameRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(wavData, sr=16000, n_mfcc=20,hop_length=int(16000/frameRate)).T\n",
    "vad = np.reshape(vad,(len(vad),))\n",
    "if mfcc.shape[0] > vad.shape[0]:\n",
    "    vad = np.hstack((vad,np.zeros(mfcc.shape[0] - vad.shape[0]).astype('bool'))).astype('bool')\n",
    "elif mfcc.shape[0] < vad.shape[0]:\n",
    "    vad = vad[:mfcc.shape[0]]\n",
    "mfcc = mfcc[vad,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb1a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = np.arange(1, 25)\n",
    "models = [GaussianMixture(n, covariance_type='full', random_state=0).fit(mfcc)\n",
    "          for n in n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(n_components, [m.bic(mfcc) for m in models], label='BIC')\n",
    "plt.plot(n_components, [m.aic(mfcc) for m in models], label='AIC')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('GMM n_components for an audio file');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGMM(wavFile, frameRate, segLen, vad, numMix):\n",
    "    wavData,_ = librosa.load(wavFile,sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(wavData, sr=16000, n_mfcc=20,hop_length=int(16000/frameRate)).T\n",
    "    vad = np.reshape(vad,(len(vad),))\n",
    "    if mfcc.shape[0] > vad.shape[0]:\n",
    "        vad = np.hstack((vad,np.zeros(mfcc.shape[0] - vad.shape[0]).astype('bool'))).astype('bool')\n",
    "    elif mfcc.shape[0] < vad.shape[0]:\n",
    "        vad = vad[:mfcc.shape[0]]\n",
    "    mfcc = mfcc[vad,:];\n",
    "    print(\"Training GMM..\")\n",
    "    GMM = GaussianMixture(n_components=numMix,covariance_type='diag').fit(mfcc)\n",
    "    var_floor = 1e-5\n",
    "    segLikes = []\n",
    "    segSize = frameRate*segLen\n",
    "    for segI in range(int(np.ceil(float(mfcc.shape[0])/(frameRate*segLen)))):\n",
    "        startI = segI*segSize\n",
    "        endI = (segI+1)*segSize\n",
    "        if endI > mfcc.shape[0]:\n",
    "            endI = mfcc.shape[0]-1\n",
    "        if endI==startI:    # Reached the end of file\n",
    "            break\n",
    "        seg = mfcc[startI:endI,:]\n",
    "        compLikes = np.sum(GMM.predict_proba(seg),0)\n",
    "        segLikes.append(compLikes/seg.shape[0])\n",
    "    print(\"Training Done\")\n",
    "\n",
    "    return np.asarray(segLikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterset = trainGMM(wavFile, frameRate, segLen, vad, numMix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a538fe5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b9bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(clusterset)  \n",
    "# Normalizing the data so that the data approximately \n",
    "# follows a Gaussian distribution\n",
    "X_normalized = normalize(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2111ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward') \n",
    "clust=cluster.fit_predict(X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086efbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SegmentFrame(clust, segLen, frameRate, numFrames):\n",
    "    frameClust = np.zeros(numFrames)\n",
    "    for clustI in range(len(clust)-1):\n",
    "        frameClust[clustI*segLen*frameRate:(clustI+1)*segLen*frameRate] = clust[clustI]*np.ones(segLen*frameRate)\n",
    "    frameClust[(clustI+1)*segLen*frameRate:] = clust[clustI+1]*np.ones(numFrames-(clustI+1)*segLen*frameRate)\n",
    "    return frameClust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c15e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameClust = SegmentFrame(clust, segLen, frameRate, mfcc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5784729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def speakerdiarisationdf(hyp, frameRate, wavFile):\n",
    "    audioname=[]\n",
    "    starttime=[]\n",
    "    endtime=[]\n",
    "    speakerlabel=[]\n",
    "    countSegments=0\n",
    "    \n",
    "    spkrChangePoints = np.where(hyp[:-1] != hyp[1:])[0]\n",
    "    if spkrChangePoints[0]!=0 and hyp[0]!=-1:\n",
    "        spkrChangePoints = np.concatenate(([0],spkrChangePoints))\n",
    "    spkrLabels = []    \n",
    "    for spkrHomoSegI in range(len(spkrChangePoints)):\n",
    "        spkrLabels.append(hyp[spkrChangePoints[spkrHomoSegI]+1])\n",
    "    for spkrI,spkr in enumerate(spkrLabels[:-1]):\n",
    "        if spkr!=-1:\n",
    "            audioname.append(wavFile.split('/')[-1].split('.')[0]+\".wav\")\n",
    "            starttime.append((spkrChangePoints[spkrI]+1)/float(frameRate))\n",
    "            endtime.append((spkrChangePoints[spkrI+1]-spkrChangePoints[spkrI])/float(frameRate))\n",
    "            speakerlabel.append(\"Speaker \"+str(int(spkr)))\n",
    "    if spkrLabels[-1]!=-1:\n",
    "        audioname.append(wavFile.split('/')[-1].split('.')[0]+\".wav\")\n",
    "        starttime.append(spkrChangePoints[-1]/float(frameRate))\n",
    "        endtime.append((len(hyp) - spkrChangePoints[-1])/float(frameRate))\n",
    "        speakerlabel.append(\"Speaker \"+str(int(spkrLabels[-1])))\n",
    "    #\n",
    "    speakerdf=pd.DataFrame({\"Audio\":audioname,\"starttime\":starttime,\"endtime\":endtime,\"speakerlabel\":speakerlabel})\n",
    "    \n",
    "    spdatafinal=pd.DataFrame(columns=['Audio','SpeakerLabel','StartTime','EndTime'])\n",
    "    i=0\n",
    "    k=0\n",
    "    j=0\n",
    "    spfind=\"\"\n",
    "    stime=\"\"\n",
    "    etime=\"\"\n",
    "    for row in speakerdf.itertuples():\n",
    "        if(i==0):\n",
    "            spfind=row.speakerlabel\n",
    "            stime=row.starttime\n",
    "        else:\n",
    "            if(spfind==row.speakerlabel):\n",
    "                etime=row.starttime        \n",
    "            else:\n",
    "                spdatafinal.loc[k]=[wavFile.split('/')[-1].split('.')[0]+\".wav\",spfind,stime,row.starttime]\n",
    "                k=k+1\n",
    "                spfind=row.speakerlabel\n",
    "                stime=row.starttime\n",
    "        i=i+1\n",
    "    \n",
    "    spdatafinal.loc[k]=[wavFile.split('/')[-1].split('.')[0]+\".wav\",spfind,stime,etime]\n",
    "    return spdatafinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c486bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass1hyp = -1*np.ones(len(vad))\n",
    "pass1hyp[vad] = frameClust\n",
    "spkdf=speakerdiarisationdf(pass1hyp, frameRate, wavFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd855d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spkdf[\"TimeSeconds\"]=spkdf.EndTime-spkdf.StartTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a91b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spkdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d85982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFileName = spkdf['Audio'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86237201",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np.size(spkdf['Audio'])):\n",
    "    newAudio = AudioSegment.from_wav(wavFile)\n",
    "    newAudio = newAudio[spkdf['StartTime'][i]*1000:spkdf['EndTime'][i]*1000]\n",
    "    newAudio.export(str(i)+'_'+audioFileName, format=\"wav\") #Exports to a wav file in the current path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37983a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
